:START_ID,type:TYPE,:END_ID,properties
ReinforcementLearning,is_designed_for,DragReduction,"{""context"": ""aerodynamic design of supercritical airfoils""}"
ReinforcementLearning,learns,Policy,"{""method"": ""trial-and-error interaction with environment""}"
Policy,takes,Action,"{""based_on"": ""StateParameter""}"
StateParameter,is_based_on,WallMachNumberDistribution,"{""purpose"": ""to make policy more general""}"
Action,modifies,Geometry,"{""parameters"": ""thickness, camber distribution, or bump modification functions""}"
Environment,provides,Reward,"{""definition"": ""drag coefficient reduction measured in Count""}"
DragReduction,measured_in,Count,"{""conversion"": ""1 count equals 0.0001 of drag coefficient""}"
Reward,is_based_on,DragReduction,"{""formula"": ""r_t = 10,000 Ã— (C_D,t - C_D,t+1)""}"
Geometry,includes,DesignParameter,"{""examples"": ""CST parameters, Hicks-Henne bump function parameters""}"
ReinforcementLearning,uses,SurrogateModel,"{""purpose"": ""fast analysis to reduce computational cost""}"
SurrogateModel,trained_on,Dataset,"{""size"": ""5,000 airfoils for training""}"
Dataset,includes,Airfoil,"{""selection_criteria"": ""features within specified range, diverse geometries""}"
Airfoil,has_property,ShockWave,"{""characteristic"": ""single shock wave""}"
Policy,is_tested_by,TestCondition,"{""method"": ""computational fluid dynamics calculations on multiple airfoils""}"
Policy,can_be_applied_to,TransferApplication,"{""result"": ""effective in training condition and other similar conditions""}"
ReinforcementLearning,improves,DragReduction,"{""measure"": ""mean drag reduction of 200 airfoils""}"
ImitationLearning,is_employed_to,Policy,"{""purpose"": ""pretraining initial policy for reinforcement learning""}"
AerodynamicDesign,depends_on,FlowCondition,"{""aspects"": ""transonic aerodynamics, designer experience""}"
ReinforcementLearning,requires,Environment,"{""components"": ""agent, action, state, reward, policy, trajectory, value""}"
Geometry,affects,PerformanceMetric,"{""metrics"": ""drag coefficient, lift coefficient, wall Mach number distribution features""}"
AlgorithmA,includes,Step,"{""description"": ""Eliminate samples not satisfying constraint, calculate distances, delete samples""}"
TrainingSet,is_part_of,Dataset,"{""size"": ""5000 samples""}"
TestingSet,is_part_of,Dataset,"{""size"": ""200 samples""}"
ANNForSurrogateModels,uses,SimulationTool,"{""tool"": ""PyTorch""}"
ANNForSurrogateModels,has_property,DesignParameter,"{""input_neurons"": 14, ""output_neurons"": 5}"
SurrogateModel,is_based_on,ANNForSurrogateModels,"{""architecture"": ""3 hidden layers, 1024 neurons each""}"
SurrogateModel,trained_on,TrainingCondition,"{""minibatch_size"": 128, ""learning_rates"": ""0.01 to 0.00001 over epochs""}"
SurrogateModel,validated_by,TestCondition,"{""metric"": ""relative root mean square error (RSME)""}"
ProximalPolicyOptimization(PPO),is_based_on,OptimizationMethod,"{""category"": ""policy gradient method""}"
PPO,uses,ActorANN,"{""role"": ""stochastic policy representation""}"
PPO,uses,CriticANN,"{""role"": ""value function representation""}"
ActorANN,has_property,DesignParameter,"{""hidden_layers"": 2, ""neurons_per_layer"": 512, ""output_size"": 3}"
CriticANN,has_property,DesignParameter,"{""hidden_layers"": 2, ""neurons_per_layer"": 512, ""output_size"": 1}"
AlgorithmC,is_employed_to,Environment,"{""purpose"": ""modify airfoil, calculate next state and reward""}"
Action,modifies,Airfoil,"{""method"": ""bump function""}"
Reward,requires,ShockWave,"{""condition"": ""Mw,1 < 1.0 results in zero reward""}"
ImitationLearning,is_based_on,Pretraining,"{""method"": ""supervised learning with demonstrations""}"
StateActionSamples,derived_from,GreedySearches,"{""source"": ""surrogate models, sample set No. 2""}"
AlgorithmD,includes,Step,"{""description"": ""Initialize parameters, generate actions, evaluate drag, select best action""}"
Policy,optimized_by,PPO,"{""initial_policy"": ""pretrained or randomly generated""}"
Policy,trained_on,Dataset,"{""sample_set"": ""No. 3, 50 airfoils, 20 trajectories each""}"
Pretraining,improves,Policy,"{""benefit"": ""avoids local optima, provides reasonable initial policy""}"
Policy,is_tested_by,CFD,"{""conditions"": ""different flow conditions, 35 typical airfoils from sample set No. 4""}"
Policy,applied_to,Airfoil,"{""count"": ""35 typical airfoils from sample set No. 4""}"
Policy,takes,Step,"{""count"": ""5 steps for each airfoil""}"
Policy,reduces,DragReduction,"{""value"": ""2.77 counts in training condition""}"
Policy,trained_on,SurrogateModel,"{""context"": ""Policy trained on surrogate models""}"
SurrogateModel,improves,Policy,"{""context"": ""Policy performance improves when more accurate surrogate models are utilized""}"
Policy,focuses_on,ShockWave,"{""context"": ""Learned policy mostly focuses on the shock wave region""}"
Policy,weakens,ShockWave,"{""context"": ""Policy can effectively weaken the shock wave""}"
Policy,works_for,Airfoil,"{""context"": ""Reinforcement learning can learn a general policy that works for different airfoils""}"
Policy,uses,WallMachNumberDistribution,"{""context"": ""Present paper uses features of airfoil wall Mach number distributions as state parameters""}"
Policy,can_be_applied_to,Airfoil,"{""context"": ""Can be applied to any supercritical airfoil in similar transonic flow conditions""}"
Policy,is_based_on,AerodynamicLaw,"{""context"": ""Learned policies can be attributed to the general laws of aerodynamics""}"
Policy,optimized_by,Algorithm,"{""algorithm"": ""Proximal Policy Optimization""}"
Policy,trained_on,ImitationLearning,"{""context"": ""Policy was pretrained through imitation learning""}"
ImitationLearning,improves,Policy,"{""context"": ""Imitation learning effectively improves the performance of reinforcement learning""}"
ReinforcementLearning,requires,SurrogateModel,"{""context"": ""Reinforcement learning requires a large number of performance evaluations, surrogate models reduce computational costs""}"
ReinforcementLearning,increases,DragReduction,"{""value"": ""From 1.34 to 5.53 counts""}"
Policy,preferably_includes,Feature,"{""context"": ""Policies preferably include physical features in state parameters""}"
Work,is_supported_by,NationalNaturalScienceFoundation,"{""grant_numbers"": ""91852108 and 11872230""}"
